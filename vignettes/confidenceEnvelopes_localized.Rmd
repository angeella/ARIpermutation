---
title: "Confidence envelopes for spatially structured hypotheses"
author: "G. Durand, G. Blanchard, P. Neuvial, E. Roquain"
date: "June 20, 2018"
output:
  html_document:
    df_print: paged
  pdf_document: default
vignette: >
  %\VignetteEngine{knitr::knitr}
  %\VignetteIndexEntry{Confidence envelopes for spatially structured hypotheses}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The goal of this vignette is to illustrate the interest of the post hoc bounds on the number of true/false positives proposed in @DBNR for localized signals. More specifically, we reproduce one of the plots of Figure 7 in @DBNR.

The parameters (whose definition is given below) are set as follows:

```{r parameters}
s <- 100
q <- 7
m <- s*2^q
K1 <- 8
r <- 0.9
m1 <-  r*K1*s
barmu <- 3
```


We consider m null ordered hypotheses partitioned in intervals of size s. For simplicity we set the number of intervals to be a power of 2: m=s2q for some integer q. Our goal is to compare three post hoc bounds. These bounds are obtained by interpolation from a *reference family* where the amount of signal is estimated by probabilistic inequalities, following the general principle laid down by @blanchard:posthoc, and they differ by the choice of the reference family:

- "Simes": the bound derived from the @simes86improved inequality as proposed by @GS2011 and further studied by @blanchard:posthoc. This bound was introduced in a context where the signal is not localized.

- "tree" and "part": two bounds derived from the DKWM inequality (@dvoretzky1956asymptotic, @massart1990tight), as proposed in @DBNR. For the "part" bound, the reference family is the original partition $(P_k)_kofthemnullhypothesesintoK=2^q$ intervals. For the "tree" bound, the reference family is the perfect binary tree whose leaves are the elements of the original partition.
We quote Section 5 of @DBNR for the definition of the true/false null hypothesis configuration:
> the false null hypotheses are contained in Pk for 1≤k≤K1, for some fixed value of K1. The  fraction of false null hypotheses in these Pk's, defined by (???), is set to [d=‘rr‘]. All of the other Pk in the partition only contain true null hypotheses. Finally,  the true null p-values are distributed as i.i.d. N(0,1), and false null p-values are distributed as i.i.d. N(μ¯,1), where [μ¯=‘rbarmu‘].  
```{r}
library("sansSouci")
```
We start by creating the binary tree structure and generating the signal:
```{r simulation}
dd <- dyadic.from.window.size(m, s, method = 2)
leaf_list <- dd$leaf_list
C <- dd$C
mu <- gen.mu.leaves(m = m, K1 = K1, d = r, grouped = TRUE, setting = "const", barmu = barmu, leaf_list = leaf_list)
```
## Confidence envelopes
We calculate post hoc confidence envelopes with level α=0.05.
```{r conf-level}
alpha <- 0.05
res <- list()
```
```{r}
pvalues <- gen.p.values(m = m, mu = mu)
ord <- order(pvalues)
idxs <- c(seq(from = 1, to = 2*m1, length = 30),
          seq(from = 2*m1, to = m, length = 10)[-1])
```
Below, we will be considering confidence envelopes of the form $(k, \bar{V}(S_k))_{1 \leq k \leq m},whereS_kisthesetoftheksmallestp$-values (regardless of the ordering given by the partition). 

### True number of false positives

The true number of false positives will be called "Oracle" bound in the plots below.

```{r oracle}
H0 <- which(mu == 0)
V <- cumsum(ord %in% H0)
V <- V[idxs]
res[["Oracle"]] <- data.frame(idxs, V, method = "Oracle")
```

### Simes-based confidence envelope

Here we use the @simes86improved inequality to bound the number of false positives in each node of the tree, as proposed by @GS2011 and further studied by @blanchard:posthoc, both in a context where the signal is not localized. 

```{r simes}
V <- idxs - sapply(idxs, FUN = function(ii) {
    posthocBySimes(pvalues, ord[1:ii], alpha)
})
res[["Simes"]] <- data.frame(idxs, V, method = "Simes")
```

### DKWM-based confidence envelope

Here we use the DKWM inequality (@dvoretzky1956asymptotic, @massart1990tight) to bound the number of false positives in each node of the tree, as suggested in @DBNR.

```{r tree}
ZL <- zetas.tree(C, leaf_list, zeta.DKWM, pvalues, alpha = alpha)
V <- sapply(idxs, FUN = function(ii) {
    V.star(ord[1:ii], C, ZL, leaf_list)
})
res[["tree"]] <- data.frame(idxs, V, method = "tree")
```

```{r}
C0 <- C[length(C)]
ZL <- zetas.tree(C0, leaf_list, zeta.DKWM, pvalues, alpha = alpha)
V <- sapply(idxs, FUN = function(ii) {
    V.star(ord[1:ii], C0, ZL, leaf_list)
})
res[["part"]] <- data.frame(idxs, V, method = "part")
```


## Confidence envelopes

```{r}
library("ggplot2")
dat <- Reduce(rbind, res)
lvls <- c("Oracle", "part", "Simes", "tree", "hybrid")
cols <- RColorBrewer::brewer.pal(length(lvls), "Set1")
names(cols) <- lvls
```


### Upper bound on the number of false positives


```{r}
xymax <- 4/3*m1;
pV <- ggplot(dat, aes(idxs, V, colour = method)) + 
    geom_line() +
    ylab("Upper bound on the number of false positives") +
    xlab("sorted hypotheses") +
    scale_colour_manual(values = cols)
```

```{r}
pV
```

The "tree" and "part" bounds are sharper than the "Simes" bound as soon as we are considering "large" sets of hypotheses.  The fact that the "tree" and "part" bounds are not as sharp as the "Simes" bound for the first hundred of hypotheses can be explained by our choice of the ordering of the null hypotheses in the sets Sk, which as discussed above is favorable to the "Simes" bound.

We zoom in the first `r xymax` null hypotheses (in the order of the p-values):

```{r warning=FALSE}
pV + xlim(1, xymax) + ylim(0, xymax)
```

## Lower bound on the number of true positives

The same information can be displayed as a lower bound on the number of true positives, defined for any $S \subset \{1 \dots m\}by|S| - \bar{V}(S)$:

```{r}
dat$S <- dat$idxs - dat$V
```

```{r}
xmax <- 4/3*m1;
ymax <- max(dat$S);
pS <- ggplot(dat, aes(idxs, S, colour = method)) + 
    geom_line() +
    ylab("Lower bound on the number of true positives") +
    xlab("sorted hypotheses") +
    scale_colour_manual(values = cols)
```

```{r}
pS
```


We zoom in the first `r xymax` null hypotheses (in the order of the p-values) to recover the middle plot in Figure 8 of @DBNR.

```{r warning=FALSE}
pS + xlim(1, xmax) + ylim(0, ymax)
```




